from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import AdaBoostClassifier
import numpy as np
import scipy.io as sio
import os


def logloss(pred_train_prob, train_labels):
    train_sample_number, train_class_number = pred_train_prob.shape
    normalized_prob = np.log(np.maximum(np.minimum(pred_train_prob, 1 - 1e-15), 1e-15))
    indicator_matrix = np.zeros(pred_train_prob.shape)
    for i in range(train_sample_number):
        indicator_matrix[i, train_labels[i] - 1] = 1

    return np.sum(np.multiply(normalized_prob, indicator_matrix)) / (-train_sample_number)


def load_data(data_path):
    # load mat
    datafile = os.path.join(data_path, 'malware_feature2.mat')

    if os.path.exists(datafile) is False:
        print('Data file %s not found.' % datafile)
        return

    data_numpy = sio.loadmat(datafile)
    # get training and test data
    train_feature = data_numpy['train_feature']
    train_labels = data_numpy['train_labels']
    test_feature = data_numpy['test_feature']
    return train_feature, train_labels, test_feature


def adaboost_clf(train_feature, train_labels, test_feature):
    ab_clf = AdaBoostClassifier(n_estimators=200)
    ab_clf.fit(train_feature, train_labels.ravel())

    print(logloss(ab_clf.predict_proba(train_feature), train_labels))
    return ab_clf.predict_proba(test_feature)


def random_classifier(train_feature, train_labels, test_feature):
    rf_clf = RandomForestClassifier(n_estimators=50)
    rf_clf.fit(train_feature, train_labels.ravel())
    test_prediction_probability = rf_clf.predict_proba(test_feature)

    print(logloss(rf_clf.predict_proba(train_feature)+1e-4, train_labels))

    return test_prediction_probability


def gradient_boost_classifier(train_feature, train_labels, test_feature):
    gb_clf = GradientBoostingClassifier()
    gb_clf.fit(train_feature, train_labels.ravel())
    test_prediction_probability = gb_clf.predict_proba(test_feature)

    print(logloss(gb_clf.predict_proba(train_feature)+1e-4, train_labels))

    return test_prediction_probability


def generate_submission(submission_filename, test_sample_filename, prediction_probability):
    test_sample_number, test_prediction_number = prediction_probability.shape
    with open(submission_filename, 'w') as fid:
        fid.write('"Id","Prediction1","Prediction2","Prediction3","Prediction4","Prediction5","Prediction6","Prediction7","Prediction8","Prediction9"\n')
        for i in range(test_sample_number):
            fid.write('\"{0}\", {1}, {2}, {3}, {4}, {5}, {6}, {7}, {8}, {9}\n'.format(test_sample_filename[i],
                                                                                      prediction_probability[i, 0],
                                                                                      prediction_probability[i, 1],
                                                                                      prediction_probability[i, 2],
                                                                                      prediction_probability[i, 3],
                                                                                      prediction_probability[i, 4],
                                                                                      prediction_probability[i, 5],
                                                                                      prediction_probability[i, 6],
                                                                                      prediction_probability[i, 7],
                                                                                      prediction_probability[i, 8]
            ))

    return

if __name__ == '__main__':
    test_sample_files = []
    test_files = os.listdir('/run/media/kewang/externalHD/Projects/kaggle/malware/test')
    for test_entry in test_files:
        if test_entry.endswith('.asm'):
            test_file_base_name, test_file_ext = os.path.splitext(test_entry)
            test_sample_files.append(test_file_base_name)

    test_sample_files.sort()

    train_features, train_labels, test_features = load_data('.')

    print('Hello random forest')
    rf_pred_proba = random_classifier(train_features, train_labels, test_features) + 0.0001
    generate_submission('rf_submission_2_hists.csv', test_sample_files, rf_pred_proba)

    print('Hello gradient boost')
    gb_pred_proba = gradient_boost_classifier(train_features, train_labels, test_features)
    generate_submission('gb_submission_2_hists.csv', test_sample_files, gb_pred_proba)

    '''
    print('Hello Adaboost')
    ab_pred_proba = adaboost_clf(train_features, train_labels, test_features)
    generate_submission('ab_submission.csv', test_sample_files, ab_pred_proba)
    '''
